{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca99c26",
   "metadata": {},
   "source": [
    "### Generate Article Using Grok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b874b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba695f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleGenerator:\n",
    "    def __init__(self, groq_api_key=None, model_name=\"Llama3-8b-8192\", vector_store_path=\"vector_db\"):\n",
    "        load_dotenv()  # Load environment variables from .env file\n",
    "        self.groq_api_key = groq_api_key or os.getenv('GROQ_API_KEY')  # Get Groq API key from argument or environment\n",
    "        if not self.groq_api_key:\n",
    "            raise ValueError(\"Groq API key not provided or found.\")\n",
    "        \n",
    "        self.llm = ChatGroq(\n",
    "            groq_api_key=self.groq_api_key,\n",
    "            model_name=model_name\n",
    "        )  # Initialize Groq LLM with API key and model name\n",
    "        self.vector_store = None\n",
    "        self.vector_store_path = vector_store_path  # Path to save/load FAISS vector store\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")  # Embedding model for semantic search\n",
    "\n",
    "        self.article_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are an expert article writer. Generate a well-structured article based on the provided title.\n",
    "        Use the following similar articles as reference to match the style, tone, and format, but create original content.\n",
    "\n",
    "        REFERENCE ARTICLES:\n",
    "        {context}\n",
    "\n",
    "        TITLE TO GENERATE ARTICLE FOR:\n",
    "        {input}\n",
    "\n",
    "        Write a comprehensive, engaging, and well-structured article for the given title. \n",
    "        The article should be factually accurate, well-researched, and follow a logical flow.\n",
    "        Include an introduction, several body paragraphs with relevant subheadings, and a conclusion.\n",
    "        Aim for approximately 800-1000 words.\n",
    "        Do not mention that you're using reference articles - write as if you are the original author.\n",
    "        \"\"\")  # Prompt template for article generation\n",
    "\n",
    "    def load_article_data(self, file_path):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)  # Load articles from CSV\n",
    "            print(f\"Loaded {len(df)} articles\")\n",
    "            if 'clean_title' not in df.columns or 'clean_text' not in df.columns:\n",
    "                raise ValueError(\"CSV must contain 'clean_title' and 'clean_text' columns\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Data loading failed: {e}\")\n",
    "            return None\n",
    "\n",
    "    def create_vector_embeddings(self, df, sample_size=None):\n",
    "\n",
    "        if sample_size is not None and len(df) > sample_size:\n",
    "            df_sample = df.sample(sample_size, random_state=42)  # Randomly sample articles if sample_size is set\n",
    "            print(f\"Using sample of {sample_size} articles for vector DB\")\n",
    "        else:\n",
    "            df_sample = df\n",
    "            print(f\"Using all {len(df_sample)} articles for vector DB\")\n",
    "\n",
    "        documents = [\n",
    "            Document(page_content=f\"Title: {row['clean_title']}\\n\\n{row['clean_text']}\", metadata={\"title\": row['clean_title']})\n",
    "            for _, row in df_sample.iterrows()\n",
    "        ]  # Create Document objects for each article\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)  # Split articles into chunks for embedding\n",
    "        chunks = splitter.split_documents(documents)\n",
    "        return FAISS.from_documents(chunks, self.embeddings)  # Build FAISS vector store from document chunks\n",
    "\n",
    "    def setup_vector_database(self, file_path, sample_size=None):\n",
    "        df = self.load_article_data(file_path)  # Load article data from CSV\n",
    "        if df is None:\n",
    "            raise ValueError(\"Article data loading failed.\")\n",
    "        print(\"Creating FAISS vector DB...\")\n",
    "        self.vector_store = self.create_vector_embeddings(df, sample_size)  # Create and store vector database\n",
    "        self.vector_store.save_local(self.vector_store_path)  # Save FAISS vector store to disk\n",
    "        print(\"Vector DB saved at:\", self.vector_store_path)\n",
    "\n",
    "    def load_vector_database(self):\n",
    "        if not os.path.exists(self.vector_store_path):\n",
    "            raise FileNotFoundError(\"Vector store not found. Run setup first.\")\n",
    "        self.vector_store = FAISS.load_local(self.vector_store_path, self.embeddings)  # Load FAISS vector store from disk\n",
    "        print(\"Vector DB loaded from disk.\")\n",
    "\n",
    "    def generate_article(self, title, num_similar_articles=3):\n",
    "        if self.vector_store is None:\n",
    "            raise ValueError(\"Vector store not loaded. Call load_vector_database() first.\")\n",
    "\n",
    "        start = time.time()  # Start timing\n",
    "\n",
    "        retriever = self.vector_store.as_retriever(search_kwargs={\"k\": num_similar_articles})  # Retrieve similar articles\n",
    "        chain = create_retrieval_chain(retriever, create_stuff_documents_chain(self.llm, self.article_prompt))  # Create retrieval and generation chain\n",
    "        response = chain.invoke({\"input\": title})  # Generate article using LLM and similar articles\n",
    "        duration = time.time() - start  # Calculate generation time\n",
    "\n",
    "        return {\n",
    "            \"title\": title,\n",
    "            \"article\": response[\"answer\"],\n",
    "            \"generation_time_seconds\": round(duration, 2)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ArticleGenerator()  # Instantiate the article generator\n",
    "generator.setup_vector_database(\"final_nlp_data.csv\", sample_size=1000)  # Build and save the vector database from CSV"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
